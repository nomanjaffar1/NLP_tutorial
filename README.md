# NLP_tutorial
# Next Word Prediction Using LSTM

## Overview

This repository contains code and notebooks for building and training a Next Word Prediction model using Long Short-Term Memory (LSTM) networks. The project includes implementations using various embeddings such as Word2Vec, GloVe, and BERT. The goal is to predict the next word in a sequence given a context.

## Project Structure

- `Next-Word-Prediction-Using-LSTM-RNN/`: Contains the main code and scripts for training and evaluating the LSTM model.
- `QA_RNN_WORD2VEC.ipynb`: Jupyter notebook for building and training the RNN model with Word2Vec embeddings.
- `QA_using_lstm.ipynb`: Jupyter notebook for using the LSTM model for next word prediction.
- `embedding_bert.ipynb`: Jupyter notebook for using BERT embeddings in the model.

## Setup

### Prerequisites

- Python 3.x
- TensorFlow
- Keras
- Numpy
- pandas
- scikit-learn
- gensim
- transformers (for BERT embeddings)

### Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/your-username/Next-Word-Prediction-Using-LSTM.git
